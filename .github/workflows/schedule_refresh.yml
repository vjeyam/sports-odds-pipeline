name: Scheduled ETL (Odds + Results)

on:
  schedule:
    # GitHub cron is UTC
    # Odds: ~07:05 CT (CST + CDT)
    - cron: "5 13 * * *"   # 07:05 CT during CST
    - cron: "5 12 * * *"   # 07:05 CT during CDT

    # Odds: ~15:05 CT
    - cron: "5 21 * * *"   # 15:05 CT during CST
    - cron: "5 20 * * *"   # 15:05 CT during CDT

    # Results: ~00:30 CT
    - cron: "30 6 * * *"   # 00:30 CT during CST
    - cron: "30 5 * * *"   # 00:30 CT during CDT

  workflow_dispatch:
    inputs:
      task:
        description: "Which task to run?"
        required: true
        default: "odds"
        type: choice
        options: [odds, results, all]

permissions:
  contents: read

concurrency:
  group: scheduled-etl
  cancel-in-progress: false

jobs:
  etl:
    runs-on: ubuntu-latest
    timeout-minutes: 20

    env:
      DATABASE_URL: ${{ secrets.DATABASE_URL }}
      SQLITE_PATH: ${{ github.workspace }}/data/demo_odds.sqlite
      PYTHONUNBUFFERED: "1"

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Decide task (odds vs results vs all)
        id: decide
        shell: bash
        run: |
          set -euo pipefail
          EVENT="${{ github.event_name }}"
          SCHEDULE="${{ github.event.schedule }}"
          INPUT_TASK="${{ inputs.task || 'odds' }}"

          TASK="odds"
          if [ "$EVENT" = "workflow_dispatch" ]; then
            TASK="$INPUT_TASK"
          elif [ "$EVENT" = "schedule" ]; then
            case "$SCHEDULE" in
              "30 6 * * *"|"30 5 * * *")
                TASK="results"
                ;;
              *)
                TASK="odds"
                ;;
            esac
          else
            TASK="odds"
          fi

          echo "task=$TASK" >> "$GITHUB_OUTPUT"
          echo "Selected task: $TASK"

      - name: Print run context
        shell: bash
        run: |
          echo "event=${{ github.event_name }}"
          echo "schedule=${{ github.event.schedule }}"
          echo "selected_task=${{ steps.decide.outputs.task }}"
          echo "sha=${{ github.sha }}"
          echo "run_id=${{ github.run_id }}"

      - name: Resolve DB target (Postgres vs SQLite)
        id: db
        shell: bash
        run: |
          set -euo pipefail

          DB_URL="${DATABASE_URL:-}"

          # Only treat as Postgres if it looks like Postgres
          if [[ "$DB_URL" == postgresql://* || "$DB_URL" == postgres://* ]]; then
            echo "db_target=$DB_URL" >> "$GITHUB_OUTPUT"
            echo "mode=postgres" >> "$GITHUB_OUTPUT"
            echo "Using Postgres DATABASE_URL."
          else
            mkdir -p data
            echo "db_target=${SQLITE_PATH}" >> "$GITHUB_OUTPUT"
            echo "mode=sqlite" >> "$GITHUB_OUTPUT"
            echo "Using SQLite at ${SQLITE_PATH}."
          fi

      - name: SQLite settings (CI-safe)
        if: steps.db.outputs.mode == 'sqlite'
        run: |
          python - <<'PY'
          import sqlite3, os
          db = os.environ["SQLITE_PATH"]
          con = sqlite3.connect(db)
          con.execute("PRAGMA journal_mode=DELETE;")
          con.execute("PRAGMA synchronous=FULL;")
          con.commit()
          con.close()
          print("Configured SQLite for CI:", db)
          PY

      - name: Ensure ODDS_API_KEY present (odds/all only)
        if: steps.decide.outputs.task == 'odds' || steps.decide.outputs.task == 'all'
        shell: bash
        run: |
          set -euo pipefail
          if [ -z "${{ secrets.ODDS_API_KEY }}" ]; then
            echo "Missing GitHub secret: ODDS_API_KEY"
            exit 1
          fi

      # Odds (with retries + skip-if-no-events)
      - name: Pull odds snapshot (retry x3)
        if: steps.decide.outputs.task == 'odds' || steps.decide.outputs.task == 'all'
        env:
          ODDS_API_KEY: ${{ secrets.ODDS_API_KEY }}
        shell: bash
        run: |
          set -euo pipefail
          for i in 1 2 3; do
            echo "Odds run attempt $i..."
            if python -m src.pipelines.run_odds_snapshot \
              --sport basketball_nba \
              --regions us \
              --db "${{ steps.db.outputs.db_target }}" \
              --skip-if-no-events; then
              echo "Odds run succeeded."
              break
            fi
            echo "Odds run failed. Sleeping before retry..."
            sleep 10
            if [ "$i" -eq 3 ]; then
              echo "Odds run failed after 3 attempts."
              exit 1
            fi
          done

      # Results + transforms (with retries)
      - name: Pull ESPN results (yesterday Chicago) (retry x3)
        if: steps.decide.outputs.task == 'results' || steps.decide.outputs.task == 'all'
        shell: bash
        run: |
          set -euo pipefail
          YDAY=$(TZ=America/Chicago date -d 'yesterday' +%Y%m%d)
          for i in 1 2 3; do
            echo "Results pull attempt $i for $YDAY..."
            if python -m src.pipelines.run_espn_results_pull \
              --db "${{ steps.db.outputs.db_target }}" \
              --date "$YDAY"; then
              echo "Results pull succeeded."
              break
            fi
            echo "Results pull failed. Sleeping before retry..."
            sleep 10
            if [ "$i" -eq 3 ]; then
              echo "Results pull failed after 3 attempts."
              exit 1
            fi
          done

      - name: Run transforms (build fact tables)
        if: steps.decide.outputs.task == 'results' || steps.decide.outputs.task == 'all'
        env:
          DBTARGET: ${{ steps.db.outputs.db_target }}
        run: |
          python - <<'PY'
          import os
          from src.pipelines.run_full_pipeline import run_transforms
          db = os.environ["DBTARGET"]
          run_transforms(db, stake=1.0, calibration_step=0.05)
          print("Transforms completed.")
          PY

      # Debug counts (SQLite only)
      - name: Debug DB counts (SQLite only)
        if: steps.db.outputs.mode == 'sqlite'
        run: |
          python - <<'PY'
          import os, sqlite3
          db = os.environ["SQLITE_PATH"]
          con = sqlite3.connect(db)
          cur = con.cursor()
          tables = [
            "raw_moneyline_odds",
            "fact_best_market_moneyline_odds",
            "raw_espn_game_results",
            "game_id_map",
            "fact_game_results_best_market",
            "fact_strategy_equity_curve",
            "etl_run_log",
          ]
          print("DB:", db)
          for t in tables:
            try:
              n = cur.execute(f"select count(*) from {t}").fetchone()[0]
              print(f"{t}: {n}")
            except Exception as e:
              print(f"{t}: (missing) {e}")
          con.close()
          PY

      # Upload db on failure (SQLite only)
      - name: Upload artifact on failure (SQLite DB)
        if: failure() && steps.db.outputs.mode == 'sqlite'
        uses: actions/upload-artifact@v4
        with:
          name: failed-demo-odds-sqlite
          path: ${{ env.SQLITE_PATH }}

      # Artifact upload (SQLite only, success only)
      - name: Upload SQLite DB artifact (SQLite only)
        if: success() && steps.db.outputs.mode == 'sqlite'
        uses: actions/upload-artifact@v4
        with:
          name: demo_odds-sqlite-${{ steps.decide.outputs.task }}
          path: ${{ env.SQLITE_PATH }}