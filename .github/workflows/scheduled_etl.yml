name: Scheduled ETL (Odds + Results)

on:
  push:
    branches: [main]

  schedule:
    # GitHub cron is UTC
    # Odds: ~07:05 CT (CST + CDT)
    - cron: "5 13 * * *"   # 07:05 CT during CST
    - cron: "5 12 * * *"   # 07:05 CT during CDT

    # Odds: ~15:05 CT
    - cron: "5 21 * * *"   # 15:05 CT during CST
    - cron: "5 20 * * *"   # 15:05 CT during CDT

    # Results: ~00:30 CT
    - cron: "30 6 * * *"   # 00:30 CT during CST
    - cron: "30 5 * * *"   # 00:30 CT during CDT

  workflow_dispatch:
    inputs:
      task:
        description: "Which task to run?"
        required: true
        default: "odds"
        type: choice
        options: [odds, results, all]

permissions:
  contents: read

concurrency:
  group: scheduled-etl
  cancel-in-progress: false

jobs:
  etl:
    runs-on: ubuntu-latest

    env:
      # Your repo secret can be odds.sqlite OR a postgres URL.
      DATABASE_URL: ${{ secrets.DATABASE_URL }}
      SQLITE_PATH: ${{ github.workspace }}/data/demo_odds.sqlite

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Decide task (odds vs results vs all)
        id: decide
        shell: bash
        run: |
          set -euo pipefail
          EVENT="${{ github.event_name }}"
          SCHEDULE="${{ github.event.schedule }}"
          INPUT_TASK="${{ inputs.task || 'odds' }}"

          TASK="odds"
          if [ "$EVENT" = "workflow_dispatch" ]; then
            TASK="$INPUT_TASK"
          elif [ "$EVENT" = "schedule" ]; then
            case "$SCHEDULE" in
              "30 6 * * *"|"30 5 * * *")
                TASK="results"
                ;;
              *)
                TASK="odds"
                ;;
            esac
          else
            TASK="odds"
          fi

          echo "task=$TASK" >> "$GITHUB_OUTPUT"
          echo "Selected task: $TASK"

      - name: Resolve DB target (Postgres vs SQLite)
        id: db
        shell: bash
        run: |
          set -euo pipefail

          DB_URL="${DATABASE_URL:-}"

          # Only treat as Postgres if it looks like Postgres
          if [[ "$DB_URL" == postgresql://* || "$DB_URL" == postgres://* ]]; then
            echo "db_target=$DB_URL" >> "$GITHUB_OUTPUT"
            echo "mode=postgres" >> "$GITHUB_OUTPUT"
            echo "Using Postgres DATABASE_URL."
          else
            mkdir -p data
            echo "db_target=${SQLITE_PATH}" >> "$GITHUB_OUTPUT"
            echo "mode=sqlite" >> "$GITHUB_OUTPUT"
            echo "Using SQLite at ${SQLITE_PATH}."
          fi

      - name: SQLite settings (CI-safe)
        if: steps.db.outputs.mode == 'sqlite'
        run: |
          python - <<'PY'
          import sqlite3, os
          db = os.environ["SQLITE_PATH"]
          con = sqlite3.connect(db)
          con.execute("PRAGMA journal_mode=DELETE;")
          con.execute("PRAGMA synchronous=FULL;")
          con.commit()
          con.close()
          print("Configured SQLite for CI:", db)
          PY

      # --------------------
      # ODDS
      # --------------------
      - name: Pull odds snapshot
        if: steps.decide.outputs.task == 'odds' || steps.decide.outputs.task == 'all'
        env:
          ODDS_API_KEY: ${{ secrets.ODDS_API_KEY }}
        run: |
          python -m src.pipelines.run_odds_snapshot \
            --sport basketball_nba \
            --regions us \
            --db "${{ steps.db.outputs.db_target }}"

      # --------------------
      # RESULTS + TRANSFORMS
      # --------------------
      - name: Pull ESPN results (yesterday Chicago)
        if: steps.decide.outputs.task == 'results' || steps.decide.outputs.task == 'all'
        run: |
          YDAY=$(TZ=America/Chicago date -d 'yesterday' +%Y%m%d)
          python -m src.pipelines.run_espn_results_pull \
            --db "${{ steps.db.outputs.db_target }}" \
            --date "$YDAY"

      - name: Run transforms (build fact tables)
        if: steps.decide.outputs.task == 'results' || steps.decide.outputs.task == 'all'
        env:
          DBTARGET: ${{ steps.db.outputs.db_target }}
        run: |
          python - <<'PY'
          import os
          from src.pipelines.run_full_pipeline import run_transforms
          db = os.environ["DBTARGET"]
          run_transforms(db, stake=1.0, calibration_step=0.05)
          print("Transforms completed.")
          PY

      # --------------------
      # DEBUG COUNTS (SQLite only)
      # --------------------
      - name: Debug DB counts (SQLite only)
        if: steps.db.outputs.mode == 'sqlite'
        run: |
          python - <<'PY'
          import os, sqlite3
          db = os.environ["SQLITE_PATH"]
          con = sqlite3.connect(db)
          cur = con.cursor()
          tables = [
            "raw_moneyline_odds",
            "fact_best_market_moneyline_odds",
            "raw_espn_game_results",
            "game_id_map",
            "fact_game_results_best_market",
            "fact_strategy_equity_curve",
          ]
          print("DB:", db)
          for t in tables:
            try:
              n = cur.execute(f"select count(*) from {t}").fetchone()[0]
              print(f"{t}: {n}")
            except Exception as e:
              print(f"{t}: (missing) {e}")
          con.close()
          PY

      # --------------------
      # ARTIFACT UPLOAD (SQLite only)
      # --------------------
      - name: Upload SQLite DB artifact (SQLite only)
        if: steps.db.outputs.mode == 'sqlite'
        uses: actions/upload-artifact@v4
        with:
          name: demo_odds-sqlite-${{ steps.decide.outputs.task }}
          path: ${{ env.SQLITE_PATH }}